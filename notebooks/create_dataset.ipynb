{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HD stands for hallucination detection.\n",
    "\n",
    "We utilize \n",
    "- the development split of CoQA with 7983 QA pairs, \n",
    "- the validation split of NQ with 3610 QA pairs, \n",
    "- the validation split of the TriviaQA (rc.nocontext subset) with 9,960 deduplicated QA pairs.\n",
    "- For the SQuAD dataset, we filter out the QA pairs with their flag is impossible = True, and utilize the subset of the developmentv2.0 split with 5928 QA pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qwj/code/HDInstruct\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"/home/qwj/hfcache\"\n",
    "os.environ['DATASETS_OFFLINE'] = '1'\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import Features, GeneratorBasedBuilder, DatasetInfo, SplitGenerator\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coqa_examples(filepath = \"./data/raw/coqa-dev-v1.0.json\"):\n",
    "    data = json.load(open(filepath))\n",
    "    for story in data['data']:\n",
    "        story_id = story['id']\n",
    "        context = story['story']\n",
    "        for i, (q, a) in enumerate(zip(story['questions'], story['answers'])):\n",
    "            additional_answers = [story['additional_answers'][str(j)][i]['input_text'] for j in range(3)]\n",
    "            answers = list(set([a['input_text']] + additional_answers))\n",
    "            yield  {\n",
    "                \"id\": f\"coqa_{story_id}_{i}\",\n",
    "                \"context\": context,\n",
    "                \"question\": q['input_text'],\n",
    "                \"ground_truth\": answers,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save preprocessed data to ./data/processed/coqa.json, total 7983 examples\n"
     ]
    }
   ],
   "source": [
    "def save_preprocessed_data_coqa(filepath, output_path):\n",
    "    processed_data = list(generate_coqa_examples(filepath))\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(processed_data, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"save preprocessed data to {output_path}, total {len(processed_data)} examples\")\n",
    "\n",
    "save_preprocessed_data_coqa(\"./data/raw/coqa-dev-v1.0.json\", \"./data/processed/coqa.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## natural questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since nq_open couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'nq_open' at /home/qwj/hfcache/datasets/nq_open/nq_open/0.0.0/3e24b5c209e8f578bd6f5ee795167a3577674383 (last modified on Fri Mar  1 09:15:18 2024).\n"
     ]
    }
   ],
   "source": [
    "# if you can reach huggingface , you can load_dataset directly\n",
    "nq_ds = datasets.load_dataset(\"nq_open\", split='validation', cache_dir=\"/home/qwj/hfcache/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save preprocessed data to ./data/processed/nq.json, total 3610 examples\n"
     ]
    }
   ],
   "source": [
    "def generate_nq_examples(nq_ds):\n",
    "    for i, example in enumerate(nq_ds):\n",
    "        yield {\n",
    "            \"id\": f\"nq_{i}\",\n",
    "            \"question\": example['question'],\n",
    "            \"ground_truth\": example['answer'],\n",
    "        }\n",
    "\n",
    "def save_preprocessed_data_nq(nq_ds, output_path):\n",
    "    processed_data = list(generate_nq_examples(nq_ds))\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(processed_data, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"save preprocessed data to {output_path}, total {len(processed_data)} examples\")\n",
    "\n",
    "save_preprocessed_data_nq(nq_ds, \"./data/processed/nq.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TriviaQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since trivia_qa couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'rc.nocontext' at /home/qwj/hfcache/datasets/trivia_qa/rc.nocontext/0.0.0/0f7faf33a3908546c6fd5b73a660e0f8ff173c2f (last modified on Wed Mar  6 12:47:32 2024).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'question_id', 'question_source', 'entity_pages', 'search_results', 'answer'],\n",
       "    num_rows: 17944\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triviaqa_ds = datasets.load_dataset(\"trivia_qa\", \"rc.nocontext\", split='validation', cache_dir=\"/home/qwj/hfcache/datasets\")\n",
    "triviaqa_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tc_33', 2),\n",
       " ('tc_40', 2),\n",
       " ('tc_49', 2),\n",
       " ('tc_56', 2),\n",
       " ('tc_106', 2),\n",
       " ('tc_137', 2),\n",
       " ('tc_217', 2),\n",
       " ('tc_219', 2),\n",
       " ('tc_241', 2),\n",
       " ('tc_261', 2)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "qid_counter = Counter()\n",
    "for example in triviaqa_ds:\n",
    "    qid_counter[example['question_id']] += 1\n",
    "qid_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question bb_956, [2767, 12171] has multiple questions:\n",
      " Name Microsoft's hands-free gaming system launched in June 2010, a made-up word alluding to joining?\n",
      "Name Microsoft's hands-free gaming system launched in November 2010, a made-up word alluding to joining?\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def generate_triviaqa_examples(triviaqa_ds):\n",
    "    qid_record = defaultdict(list)\n",
    "    for i, example in enumerate(triviaqa_ds):\n",
    "        qid_record[example['question_id']].append(i)\n",
    "    for qid, indices in qid_record.items():\n",
    "        # assert questions are the same\n",
    "        all_questions, all_answers = set(), set()\n",
    "        for i in indices:\n",
    "            all_questions.add(triviaqa_ds[i]['question'])\n",
    "            all_answers.add(triviaqa_ds[i]['answer']['value'])\n",
    "            for alias in triviaqa_ds[i]['answer']['aliases']:\n",
    "                all_answers.add(alias)\n",
    "        if len(all_questions) != 1:\n",
    "            print(f\"question {qid}, {indices} has multiple questions:\\n\",'\\n'.join(all_questions))\n",
    "            continue\n",
    "        yield {\n",
    "            \"id\": f\"triviaqa_{qid}\",\n",
    "            \"question\": list(all_questions),\n",
    "            \"ground_truth\": list(all_answers),\n",
    "        }\n",
    "\n",
    "shit = list(generate_triviaqa_examples(triviaqa_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Kinect', 'Kinect')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triviaqa_ds[2767]['answer']['value'], triviaqa_ds[12171]['answer']['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Wikipedia\n",
    "\n",
    "Release date\tXbox 360\n",
    "NA: November 4, 2010[2]\n",
    "EU: November 10, 2010[1]\n",
    "COL: November 14, 2010[3]\n",
    "AU: November 18, 2010[4]\n",
    "JP: November 20, 2010[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip one unexpected error question: 2767 Name Microsoft's hands-free gaming system launched in June 2010, a made-up word alluding to joining?\n",
      "total 9960 examples\n",
      "save preprocessed data to ./data/processed/triviaqa.json\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def generate_triviaqa_examples(triviaqa_ds):\n",
    "    qid_record = defaultdict(list)\n",
    "    for i, example in enumerate(triviaqa_ds):\n",
    "        if i == 2767:\n",
    "            print('skip one unexpected error question:', i, example['question'])\n",
    "            continue\n",
    "        qid_record[example['question_id']].append(i)\n",
    "    for qid, indices in qid_record.items():\n",
    "        # assert questions are the same\n",
    "        all_questions, all_answers = set(), set()\n",
    "        for i in indices:\n",
    "            all_questions.add(triviaqa_ds[i]['question'])\n",
    "            all_answers.add(triviaqa_ds[i]['answer']['value'])\n",
    "            for alias in triviaqa_ds[i]['answer']['aliases']:\n",
    "                all_answers.add(alias)\n",
    "        assert len(all_questions) == 1\n",
    "        yield {\n",
    "            \"id\": f\"triviaqa_{qid}\",\n",
    "            \"question\": list(all_questions)[0],\n",
    "            \"ground_truth\": list(all_answers),\n",
    "        }\n",
    "\n",
    "processed_data = list(generate_triviaqa_examples(triviaqa_ds))\n",
    "print(f\"total {len(processed_data)} examples\")\n",
    "with open(\"./data/processed/triviaqa.json\", 'w') as f:\n",
    "    json.dump(processed_data, f, ensure_ascii=False, indent=4)\n",
    "print(f\"save preprocessed data to ./data/processed/triviaqa.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5928 examples\n",
      "save preprocessed data to ./data/processed/squad.json\n"
     ]
    }
   ],
   "source": [
    "def generate_squad_examples(filepath = \"./data/raw/squad-dev-v2.0.json\"):\n",
    "    data = json.load(open(filepath))\n",
    "    for article in data['data']:\n",
    "        for paragraph in article['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                if qa['is_impossible']:\n",
    "                    continue\n",
    "                question = qa['question']\n",
    "                answers = set([a['text'] for a in qa['answers']])\n",
    "                yield {\n",
    "                    \"id\": f\"squad_{qa['id']}\",\n",
    "                    \"context\": context,\n",
    "                    \"question\": question,\n",
    "                    \"ground_truth\": list(answers),\n",
    "                }\n",
    "\n",
    "processed_data = list(generate_squad_examples())\n",
    "print(f\"total {len(processed_data)} examples\")\n",
    "with open(\"./data/processed/squad.json\", 'w') as f:\n",
    "    json.dump(processed_data, f, ensure_ascii=False, indent=4)\n",
    "print(f\"save preprocessed data to ./data/processed/squad.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "generate 100 samples from each dataset for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "# for dname in ['coqa', 'nq', 'triviaqa', 'squad']:\n",
    "for dname in ['triviaqa']:\n",
    "    with open(f\"./data/processed/{dname}.json\") as f:\n",
    "        data = json.load(f)\n",
    "    # select 100 examples for each dataset\n",
    "    selected = random.sample(data, 100)\n",
    "    with open(f\"./data/debug/{dname}_sample.json\", 'w') as f:\n",
    "        json.dump(selected, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
