{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qwj/code/HDInstruct\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./outputs/completion_few_shot_full_2024-03-11_13-27\"\n",
    "file_suffix = \"_uncertainty.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(title, df):\n",
    "    table = PrettyTable()\n",
    "    table.title = title\n",
    "    table.field_names = [\"Uncertainty Methods\",  \"AUC_R\", \"AUC_S\",\"PCC\"]\n",
    "\n",
    "    pos_or_neg = {\n",
    "        'perplexity': 'neg',\n",
    "        'energy_score': 'pos',\n",
    "        'ln_entropy': 'neg',\n",
    "        'lexical_similarity': 'pos',\n",
    "        'eigen_score': 'neg',\n",
    "    }\n",
    "\n",
    "    for uncertainty, flag in pos_or_neg.items():\n",
    "        if flag == 'pos':\n",
    "            aus_s = roc_auc_score(df['similarity_correctness'], df[uncertainty])\n",
    "            aus_r = roc_auc_score(df['rouge_correctness'], df[uncertainty])\n",
    "        else:\n",
    "            aus_s = roc_auc_score(df['similarity_correctness'], -df[uncertainty])\n",
    "            aus_r = roc_auc_score(df['rouge_correctness'], -df[uncertainty])\n",
    "        pearson_r = abs(pearsonr(df[uncertainty], df['rouge_correctness'])[0])\n",
    "        table.add_row([uncertainty, f\"{aus_r*100:.2f}\", f\"{aus_s*100:.2f}\", f\"{pearson_r*100:.2f}\"])\n",
    "    table.reversesort = True\n",
    "    print(table)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>ln_entropy</th>\n",
       "      <th>energy_score</th>\n",
       "      <th>eigen_score</th>\n",
       "      <th>lexical_similarity</th>\n",
       "      <th>rouge_correctness</th>\n",
       "      <th>similarity_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coqa_3dr23u6we5exclen4th8uq9rb42tel_0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.564141</td>\n",
       "      <td>1.564141</td>\n",
       "      <td>-1.879919</td>\n",
       "      <td>0.522871</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coqa_3dr23u6we5exclen4th8uq9rb42tel_1</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.904711</td>\n",
       "      <td>0.904711</td>\n",
       "      <td>-2.903833</td>\n",
       "      <td>0.555896</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coqa_3dr23u6we5exclen4th8uq9rb42tel_2</td>\n",
       "      <td>0.860375</td>\n",
       "      <td>0.978429</td>\n",
       "      <td>0.978429</td>\n",
       "      <td>-5.009766</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coqa_3dr23u6we5exclen4th8uq9rb42tel_3</td>\n",
       "      <td>0.809057</td>\n",
       "      <td>1.167674</td>\n",
       "      <td>1.167674</td>\n",
       "      <td>-3.112764</td>\n",
       "      <td>0.429333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coqa_3dr23u6we5exclen4th8uq9rb42tel_4</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.129405</td>\n",
       "      <td>1.129405</td>\n",
       "      <td>-0.828460</td>\n",
       "      <td>0.377347</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id   perplexity  ln_entropy  \\\n",
       "0  coqa_3dr23u6we5exclen4th8uq9rb42tel_0  1000.000000    1.564141   \n",
       "1  coqa_3dr23u6we5exclen4th8uq9rb42tel_1  1000.000000    0.904711   \n",
       "2  coqa_3dr23u6we5exclen4th8uq9rb42tel_2     0.860375    0.978429   \n",
       "3  coqa_3dr23u6we5exclen4th8uq9rb42tel_3     0.809057    1.167674   \n",
       "4  coqa_3dr23u6we5exclen4th8uq9rb42tel_4  1000.000000    1.129405   \n",
       "\n",
       "   energy_score  eigen_score  lexical_similarity  rouge_correctness  \\\n",
       "0      1.564141    -1.879919            0.522871              False   \n",
       "1      0.904711    -2.903833            0.555896              False   \n",
       "2      0.978429    -5.009766            1.000000               True   \n",
       "3      1.167674    -3.112764            0.429333              False   \n",
       "4      1.129405    -0.828460            0.377347              False   \n",
       "\n",
       "   similarity_correctness  \n",
       "0                   False  \n",
       "1                   False  \n",
       "2                    True  \n",
       "3                   False  \n",
       "4                   False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(os.path.join(data_dir, \"coqa\" + file_suffix), lines=True, orient=\"records\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|                     CoQA                    |\n",
      "+---------------------+-------+-------+-------+\n",
      "| Uncertainty Methods | AUC_R | AUC_S |  PCC  |\n",
      "+---------------------+-------+-------+-------+\n",
      "|      perplexity     | 69.01 | 68.99 | 50.07 |\n",
      "|     energy_score    | 32.98 | 33.04 | 29.58 |\n",
      "|      ln_entropy     | 67.02 | 66.96 | 29.58 |\n",
      "|  lexical_similarity | 80.50 | 80.89 | 51.55 |\n",
      "|     eigen_score     | 80.08 | 82.20 | 52.20 |\n",
      "+---------------------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "print_result(\"CoQA\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>ln_entropy</th>\n",
       "      <th>energy_score</th>\n",
       "      <th>eigen_score</th>\n",
       "      <th>lexical_similarity</th>\n",
       "      <th>rouge_correctness</th>\n",
       "      <th>similarity_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>squad_56ddde6b9a695914005b9628</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>-6.251751</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>squad_56ddde6b9a695914005b9629</td>\n",
       "      <td>0.060648</td>\n",
       "      <td>0.101328</td>\n",
       "      <td>0.101328</td>\n",
       "      <td>-5.675595</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>squad_56ddde6b9a695914005b962a</td>\n",
       "      <td>0.121977</td>\n",
       "      <td>0.182097</td>\n",
       "      <td>0.182097</td>\n",
       "      <td>-4.786143</td>\n",
       "      <td>0.817253</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>squad_56ddde6b9a695914005b962b</td>\n",
       "      <td>0.046122</td>\n",
       "      <td>0.046122</td>\n",
       "      <td>0.046122</td>\n",
       "      <td>-6.250949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>squad_56ddde6b9a695914005b962c</td>\n",
       "      <td>0.238863</td>\n",
       "      <td>0.193989</td>\n",
       "      <td>0.193989</td>\n",
       "      <td>-5.537917</td>\n",
       "      <td>0.840351</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id  perplexity  ln_entropy  energy_score  \\\n",
       "0  squad_56ddde6b9a695914005b9628    0.128348    0.128348      0.128348   \n",
       "1  squad_56ddde6b9a695914005b9629    0.060648    0.101328      0.101328   \n",
       "2  squad_56ddde6b9a695914005b962a    0.121977    0.182097      0.182097   \n",
       "3  squad_56ddde6b9a695914005b962b    0.046122    0.046122      0.046122   \n",
       "4  squad_56ddde6b9a695914005b962c    0.238863    0.193989      0.193989   \n",
       "\n",
       "   eigen_score  lexical_similarity  rouge_correctness  similarity_correctness  \n",
       "0    -6.251751            1.000000               True                    True  \n",
       "1    -5.675595            0.966667               True                    True  \n",
       "2    -4.786143            0.817253               True                    True  \n",
       "3    -6.250949            1.000000               True                    True  \n",
       "4    -5.537917            0.840351               True                    True  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(os.path.join(data_dir, \"squad\" + file_suffix), lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|                    SQuAD                    |\n",
      "+---------------------+-------+-------+-------+\n",
      "| Uncertainty Methods | AUC_R | AUC_S |  PCC  |\n",
      "+---------------------+-------+-------+-------+\n",
      "|      perplexity     | 65.77 | 67.91 | 15.30 |\n",
      "|     energy_score    | 26.82 | 25.96 | 37.59 |\n",
      "|      ln_entropy     | 73.18 | 74.04 | 37.59 |\n",
      "|  lexical_similarity | 82.55 | 81.64 | 54.20 |\n",
      "|     eigen_score     | 80.20 | 81.58 | 52.86 |\n",
      "+---------------------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "print_result(\"SQuAD\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>ln_entropy</th>\n",
       "      <th>energy_score</th>\n",
       "      <th>eigen_score</th>\n",
       "      <th>lexical_similarity</th>\n",
       "      <th>rouge_correctness</th>\n",
       "      <th>similarity_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nq_0</td>\n",
       "      <td>0.046152</td>\n",
       "      <td>0.046152</td>\n",
       "      <td>0.046152</td>\n",
       "      <td>-6.249629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nq_1</td>\n",
       "      <td>0.889976</td>\n",
       "      <td>0.953212</td>\n",
       "      <td>0.953212</td>\n",
       "      <td>-3.919195</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nq_2</td>\n",
       "      <td>0.098977</td>\n",
       "      <td>0.098977</td>\n",
       "      <td>0.098977</td>\n",
       "      <td>-6.245945</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nq_3</td>\n",
       "      <td>0.393730</td>\n",
       "      <td>0.647165</td>\n",
       "      <td>0.647165</td>\n",
       "      <td>-4.312772</td>\n",
       "      <td>0.163158</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nq_4</td>\n",
       "      <td>1.045260</td>\n",
       "      <td>1.262186</td>\n",
       "      <td>1.262186</td>\n",
       "      <td>-1.205522</td>\n",
       "      <td>0.128574</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  perplexity  ln_entropy  energy_score  eigen_score  \\\n",
       "0  nq_0    0.046152    0.046152      0.046152    -6.249629   \n",
       "1  nq_1    0.889976    0.953212      0.953212    -3.919195   \n",
       "2  nq_2    0.098977    0.098977      0.098977    -6.245945   \n",
       "3  nq_3    0.393730    0.647165      0.647165    -4.312772   \n",
       "4  nq_4    1.045260    1.262186      1.262186    -1.205522   \n",
       "\n",
       "   lexical_similarity  rouge_correctness  similarity_correctness  \n",
       "0            1.000000               True                   False  \n",
       "1            0.292481               True                    True  \n",
       "2            1.000000              False                   False  \n",
       "3            0.163158              False                   False  \n",
       "4            0.128574              False                   False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(os.path.join(data_dir, \"nq\" + file_suffix), lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|              Natural Questions              |\n",
      "+---------------------+-------+-------+-------+\n",
      "| Uncertainty Methods | AUC_R | AUC_S |  PCC  |\n",
      "+---------------------+-------+-------+-------+\n",
      "|      perplexity     | 73.12 | 72.56 | 29.52 |\n",
      "|     energy_score    | 24.99 | 25.46 | 35.91 |\n",
      "|      ln_entropy     | 75.01 | 74.54 | 35.91 |\n",
      "|  lexical_similarity | 80.88 | 80.73 | 48.18 |\n",
      "|     eigen_score     | 77.09 | 79.67 | 39.82 |\n",
      "+---------------------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "print_result(\"Natural Questions\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TriviaQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>ln_entropy</th>\n",
       "      <th>energy_score</th>\n",
       "      <th>eigen_score</th>\n",
       "      <th>lexical_similarity</th>\n",
       "      <th>rouge_correctness</th>\n",
       "      <th>similarity_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>triviaqa_tc_2</td>\n",
       "      <td>0.147896</td>\n",
       "      <td>0.373409</td>\n",
       "      <td>0.373409</td>\n",
       "      <td>-4.590501</td>\n",
       "      <td>0.654737</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>triviaqa_tc_33</td>\n",
       "      <td>0.519650</td>\n",
       "      <td>0.767348</td>\n",
       "      <td>0.767348</td>\n",
       "      <td>-3.417020</td>\n",
       "      <td>0.273544</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>triviaqa_tc_40</td>\n",
       "      <td>0.422261</td>\n",
       "      <td>0.847624</td>\n",
       "      <td>0.847624</td>\n",
       "      <td>-1.023559</td>\n",
       "      <td>0.138583</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>triviaqa_tc_49</td>\n",
       "      <td>0.244038</td>\n",
       "      <td>0.329107</td>\n",
       "      <td>0.329107</td>\n",
       "      <td>-5.603721</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>triviaqa_tc_56</td>\n",
       "      <td>0.447769</td>\n",
       "      <td>0.807017</td>\n",
       "      <td>0.807017</td>\n",
       "      <td>-4.255697</td>\n",
       "      <td>0.475088</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  perplexity  ln_entropy  energy_score  eigen_score  \\\n",
       "0   triviaqa_tc_2    0.147896    0.373409      0.373409    -4.590501   \n",
       "1  triviaqa_tc_33    0.519650    0.767348      0.767348    -3.417020   \n",
       "2  triviaqa_tc_40    0.422261    0.847624      0.847624    -1.023559   \n",
       "3  triviaqa_tc_49    0.244038    0.329107      0.329107    -5.603721   \n",
       "4  triviaqa_tc_56    0.447769    0.807017      0.807017    -4.255697   \n",
       "\n",
       "   lexical_similarity  rouge_correctness  similarity_correctness  \n",
       "0            0.654737              False                   False  \n",
       "1            0.273544              False                   False  \n",
       "2            0.138583              False                   False  \n",
       "3            0.900000              False                   False  \n",
       "4            0.475088              False                   False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(os.path.join(data_dir, \"triviaqa\" + file_suffix), lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|                   TriviaQA                  |\n",
      "+---------------------+-------+-------+-------+\n",
      "| Uncertainty Methods | AUC_R | AUC_S |  PCC  |\n",
      "+---------------------+-------+-------+-------+\n",
      "|      perplexity     | 79.86 | 79.61 | 47.02 |\n",
      "|     energy_score    | 17.21 | 18.28 | 54.57 |\n",
      "|      ln_entropy     | 82.79 | 81.72 | 54.57 |\n",
      "|  lexical_similarity | 88.00 | 86.49 | 64.26 |\n",
      "|     eigen_score     | 85.20 | 86.26 | 60.65 |\n",
      "+---------------------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "print_result(\"TriviaQA\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rouge_correctness</th>\n",
       "      <th>similarity_correctness</th>\n",
       "      <th>logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>triviaqa_tc_2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[9.3197774887, -7.8463964462]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>triviaqa_tc_33</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[9.523311615, -7.3078994751]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>triviaqa_tc_40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[9.3080377579, -7.3941273688999996]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>triviaqa_tc_49</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[9.3530950546, -8.2431402206]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>triviaqa_tc_56</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[9.4434719086, -8.2656526566]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  rouge_correctness  similarity_correctness  \\\n",
       "0   triviaqa_tc_2              False                   False   \n",
       "1  triviaqa_tc_33              False                   False   \n",
       "2  triviaqa_tc_40              False                   False   \n",
       "3  triviaqa_tc_49              False                   False   \n",
       "4  triviaqa_tc_56              False                   False   \n",
       "\n",
       "                                logits  \n",
       "0        [9.3197774887, -7.8463964462]  \n",
       "1         [9.523311615, -7.3078994751]  \n",
       "2  [9.3080377579, -7.3941273688999996]  \n",
       "3        [9.3530950546, -8.2431402206]  \n",
       "4        [9.4434719086, -8.2656526566]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(os.path.join(data_dir, \"triviaqa_correctness_logits.jsonl\"), lines=True, orient=\"records\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.32543600051105,\n",
       " 4.298663640720983,\n",
       " 4.863361321092657,\n",
       " 8.426554638168279,\n",
       " 8.017759849454395]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = df['logits'].apply(lambda x: x[0]/(x[0]+x[1]))\n",
    "probs = probs.to_list()\n",
    "probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5188627743030793"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(df['rouge_correctness'], probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5300154702186318"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(df['similarity_correctness'], probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0050030740489649325"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(pearsonr(probs, df['rouge_correctness'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "preds = df['logits'].apply(lambda x: np.argmax(x))\n",
    "preds = preds.to_list()\n",
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds)/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
